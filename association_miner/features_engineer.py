import numpy as np
import pandas as pd
import talib

from utils.base_logger import BaseLogger


class Features(BaseLogger):
    """–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Å–≤–µ—á–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: base ‚Üí volume ‚Üí sequences ‚Üí target"""

    def __init__(self, verbose: bool = False):
        """verbose=True ‚Üí INFO –ª–æ–≥–∏ | ERROR –≤—Å–µ–≥–¥–∞ –∞–∫—Ç–∏–≤–Ω—ã"""
        super().__init__(verbose)



    def _log_features(self, features: pd.DataFrame, stage: str = "features"):
        """–õ–æ–≥–≥–µ—Ä –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ñ–∏—á (—Ç–æ–ª—å–∫–æ INFO)"""
        if not self.verbose:
            return
        binary_cols = features.select_dtypes(include=['int64']).columns.tolist()
        self._log_info(f" ‚úÖ {len(binary_cols)} –±–∏–Ω–∞—Ä–Ω—ã—Ö {stage}!")

    def calculate_atr(self, df: pd.DataFrame, period: int = 14) -> pd.Series:
        high, low, close = df['high'], df['low'], df['close']
        atr = talib.ATR(high.values, low.values, close.values, timeperiod=period)
        return pd.Series(atr, index=df.index).bfill()

    def create_candle_features(self, df: pd.DataFrame) -> pd.DataFrame:
        o, h, l, c = df['open'], df['high'], df['low'], df['close']
        features = pd.DataFrame(index=df.index)

        # –ë–ê–ó–û–í–´–ï –†–ê–ó–ú–ï–†–´
        features['body_size'] = abs(c - o)
        features['upper_shadow'] = h - np.maximum(c, o)
        features['lower_shadow'] = np.minimum(c, o) - l
        features['total_range'] = h - l

        # % –û–¢ –†–ï–ô–ù–î–ñ–ê
        features['body_pct'] = features['body_size'] / features['total_range'].replace(0, np.nan)
        features['upper_shadow_pct'] = features['upper_shadow'] / features['total_range'].replace(0, np.nan)
        features['lower_shadow_pct'] = features['lower_shadow'] / features['total_range'].replace(0, np.nan)

        # –ü–û–ó–ò–¶–ò–Ø CLOSE
        features['close_top_30'] = (c >= h - (h - l) * 0.3).astype(int)
        features['close_bottom_30'] = (c <= l + (h - l) * 0.3).astype(int)
        features['close_middle'] = ((features['close_top_30'] == 0) & (features['close_bottom_30'] == 0)).astype(int)

        # –°–í–ï–ß–ù–´–ï –ü–ê–¢–¢–ï–†–ù–´
        features['doji'] = (features['body_pct'] < 0.1).astype(int)
        features['marubozu'] = (features['body_pct'] > 0.9).astype(int)
        features['hammer'] = ((features['lower_shadow_pct'] > 0.6) & (features['body_pct'] < 0.3)).astype(int)
        features['shooting_star'] = ((features['upper_shadow_pct'] > 0.6) & (features['body_pct'] < 0.3)).astype(int)
        features['spinning_top'] = ((features['body_pct'] < 0.2) &
                                    (features['upper_shadow_pct'] > 0.2) &
                                    (features['lower_shadow_pct'] > 0.2)).astype(int)
        features['small_body'] = (features['body_pct'] < 0.3).astype(int)

        # –ù–ê–ü–†–ê–í–õ–ï–ù–ò–ï + –¢–ï–ù–ò
        features['bullish'] = (c > o).astype(int)
        features['bearish'] = (c < o).astype(int)
        features['upper_shadow_long'] = (features['upper_shadow_pct'] > 0.4).astype(int)
        features['lower_shadow_long'] = (features['lower_shadow_pct'] > 0.4).astype(int)

        # ATR –°–†–ê–í–ù–ï–ù–ò–ï
        atr = self.calculate_atr(df, 14)
        features['atr_high'] = (features['total_range'] > atr * 1.5).astype(int)
        features['atr_low'] = (features['total_range'] < atr * 0.5).astype(int)

        # –ë–û–õ–¨–®–ò–ï –¢–ï–õ–ê
        features['big_green'] = ((features['bullish'] == 1) & (features['body_pct'] > 0.6)).astype(int)
        features['big_red'] = ((features['bearish'] == 1) & (features['body_pct'] > 0.6)).astype(int)

        # üî• ORDER BLOCKS (SMC)
        h1, l1, c1 = h.shift(1), l.shift(1), c.shift(1)
        o1 = o.shift(1)

        # ‚úÖ BULLISH OB: –ú–µ–¥–≤–µ–∂—å—è —Å–≤–µ—á–∞ + —Å–∏–ª—å–Ω—ã–π —Ä–æ—Å—Ç
        features['is_bullish_ob'] = (
                (c1 < o1) &  # –ü—Ä–µ–¥—ã–¥—É—â–∞—è —Å–≤–µ—á–∞ –º–µ–¥–≤–µ–∂—å—è (–∫—Ä–∞—Å–Ω–∞—è)
                (c > h1 * 1.002)  # –¢–µ–∫—É—â–∞—è –ø—Ä–æ–±–∏–ª–∞ high –ø—Ä–µ–¥—ã–¥—É—â–µ–π
        ).astype(int)

        # ‚úÖ BEARISH OB: –ë—ã—á—å—è —Å–≤–µ—á–∞ + —Å–∏–ª—å–Ω–æ–µ –ø–∞–¥–µ–Ω–∏–µ
        features['is_bearish_ob'] = (
                (c1 > o1) &  # –ü—Ä–µ–¥—ã–¥—É—â–∞—è —Å–≤–µ—á–∞ –±—ã—á—å—è (–∑–µ–ª–µ–Ω–∞—è)
                (c < l1 * 0.998)  # –¢–µ–∫—É—â–∞—è –ø—Ä–æ–±–∏–ª–∞ low –ø—Ä–µ–¥—ã–¥—É—â–µ–π
        ).astype(int)

        self._log_features(features, "–ë–ê–ó–û–í–´–• —Å–≤–µ—á–Ω—ã—Ö")
        return features

    def add_volume_combos(self, candle_features: pd.DataFrame, df: pd.DataFrame) -> pd.DataFrame:
        features = candle_features.copy()
        tv = df['tick_volume']

        # VOLUME –ë–ê–ó–û–í–´–ï
        features['vol_variation'] = (tv - tv.shift(1)).fillna(0)
        features['vol_spike'] = (features['vol_variation'] > tv.shift(1) * 1.9).fillna(0).astype(int)
        features['vol_drop'] = (features['vol_variation'] < -tv.shift(1) * 1.9).fillna(0).astype(int)
        features['vol_up'] = (features['vol_variation'] > tv.shift(1) * 0.2).fillna(0).astype(int)
        features['vol_down'] = (features['vol_variation'] < -tv.shift(1) * 0.2).fillna(0).astype(int)

        # –î–ò–ù–ê–ú–ò–ß–ï–°–ö–ò: –í–°–ï binary √ó vol_types
        binary_patterns = candle_features.select_dtypes(include=['int64']).columns.tolist()
        vol_types = ['vol_spike', 'vol_drop', 'vol_up', 'vol_down']

        for pattern in binary_patterns:
            for vol_type in vol_types:
                new_feature = f'{pattern}_{vol_type}'
                features[new_feature] = (features[pattern] & features[vol_type]).astype(int)

        self._log_features(features, "VOLUME_–ö–û–ú–ë–û")
        return features

    def add_sequences(self, features: pd.DataFrame, df: pd.DataFrame) -> pd.DataFrame:
        seq_features = features.copy()
        o, h, l, c = df['open'], df['high'], df['low'], df['close']
        o1, h1, l1, c1 = o.shift(1), h.shift(1), l.shift(1), c.shift(1)

        # Base patterns –¥–ª—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π
        binary_cols = features.select_dtypes(include=['int64']).columns.tolist()
        base_patterns = [col for col in binary_cols
                         if not col.startswith('vol_')
                         and col not in ['next_up', 'next_down']
                         and (features[col] == 1).sum() > 45]

        self._log_info(f"üîÑ –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º {len(base_patterns)}^2 = {len(base_patterns) ** 2} –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π...")

        sequence_columns = []

        # –î–ò–ù–ê–ú–ò–ß–ï–°–ö–ò–ï –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        for pat1 in base_patterns:
            for pat2 in base_patterns:
                seq_col = (
                        features[pat1].shift(1).fillna(0).astype(int) &
                        features[pat2].fillna(0).astype(int)
                )
                sequence_columns.append(seq_col.rename(f'{pat1}_prev_{pat2}'))

        # CLASSIC PATTERNS
        sequence_columns.extend([
            ((l < l1) & (features['vol_spike'] == 1) & (c > l * 1.002)).astype(int).rename('exhaustion_min'),
            ((h > h1) & (features['vol_spike'] == 1) & (c < h * 0.998)).astype(int).rename('exhaustion_max'),
            ((c1 < o1) & (c > o) & (o < c1) & (c > o1)).astype(int).rename('bullish_engulfing'),
            ((c1 > o1) & (c < o) & (o > c1) & (c < o1)).astype(int).rename('bearish_engulfing'),
            ((h < h1) & (l > l1)).astype(int).rename('inside_bar'),
            ((h > h1) & (l < l1)).astype(int).rename('outside_bar'),
            (h > h1).astype(int).rename('higher_high'),
            (l > l1).astype(int).rename('higher_low'),
            (h < h1).astype(int).rename('lower_high'),
            (l < l1).astype(int).rename('lower_low')
        ])

        # EQUAL EXTREMES
        equal_extremes = self.add_equal_extremes(features, df)
        for col in equal_extremes.columns:
            sequence_columns.append(equal_extremes[col])

        new_seq_df = pd.concat(sequence_columns, axis=1)
        result = pd.concat([seq_features, new_seq_df], axis=1)
        result = result.loc[:, ~result.columns.duplicated()]

        self._log_features(result, "–ü–û–°–õ–ï–î–û–í–ê–¢–ï–õ–¨–ù–û–°–¢–ï–ô")
        return result

    def add_equal_extremes(self, features: pd.DataFrame, df: pd.DataFrame) -> pd.DataFrame:
        """üî• –†–∞–≤–Ω—ã–µ —ç–∫—Å—Ç—Ä–µ–º—É–º—ã (–¥–≤–æ–π–Ω—ã–µ/—Ç—Ä–æ–π–Ω—ã–µ –≤–µ—Ä—à–∏–Ω—ã-–¥–Ω–∏—â–∞)"""
        h, l, c = df['high'], df['low'], df['close']

        # Shifted highs/lows
        h1, l1 = h.shift(1), l.shift(1)
        h2, l2 = h.shift(2), l.shift(2)
        h3, l3 = h.shift(3), l.shift(3)

        result = pd.DataFrame(index=features.index)

        # –î–≤–æ–π–Ω—ã–µ –≤–µ—Ä—à–∏–Ω—ã (highs –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö 0.05%)
        result['double_top'] = (
                (h >= h1 * 0.9995) & (h1 >= h2 * 0.999) &
                (c < h * 0.998)  # –ó–∞–∫—Ä—ã—Ç–∏–µ –Ω–∏–∂–µ –≤–µ—Ä—à–∏–Ω—ã
        ).astype(int)

        # –î–≤–æ–π–Ω—ã–µ –¥–Ω–∏—â–∞
        result['double_bottom'] = (
                (l <= l1 * 1.0005) & (l1 <= l2 * 1.001) &
                (c > l * 1.002)  # –ó–∞–∫—Ä—ã—Ç–∏–µ –≤—ã—à–µ –¥–Ω–∞
        ).astype(int)

        # –¢—Ä–æ–π–Ω—ã–µ
        result['triple_top'] = (
                (h >= h1 * 0.9995) & (h >= h2 * 0.999) & (h >= h3 * 0.998)
        ).astype(int)
        result['triple_bottom'] = (
                (l <= l1 * 1.0005) & (l <= l2 * 1.001) & (l <= l3 * 1.002)
        ).astype(int)

        # –° volume —Å–ø–∞–π–∫–æ–º
        if 'vol_spike' in features.columns:
            result['double_top_vol'] = (result['double_top'] & features['vol_spike']).astype(int)
            result['double_bottom_vol'] = (result['double_bottom'] & features['vol_spike']).astype(int)

        self._log_features(result, "EQUAL_EXTREMES")
        return result

    def add_trend_ma(self, df: pd.DataFrame, features: pd.DataFrame) -> pd.DataFrame:
        ma21 = df['close'].rolling(21).mean()
        ma50 = df['close'].rolling(50).mean()
        ma200 = df['close'].rolling(200).mean()

        features['ma_bull_21_50'] = (ma21 > ma50).astype(int)
        features['ma_bear_21_50'] = (ma21 < ma50).astype(int)
        features['ma_bull_all'] = ((ma21 > ma50) & (ma50 > ma200)).astype(int)
        features['ma_bear_all'] = ((ma21 < ma50) & (ma50 < ma200)).astype(int)

        features['price_above_all_ma'] = ((df['close'] > ma21) & (df['close'] > ma50) & (df['close'] > ma200)).astype(
            int)
        features['price_below_all_ma'] = ((df['close'] < ma21) & (df['close'] < ma50) & (df['close'] < ma200)).astype(
            int)

        features['bearish_below_all_ma'] = (features['bearish'] & features['price_below_all_ma']).astype(int)
        features['bullish_above_all_ma'] = (features['bullish'] & features['price_above_all_ma']).astype(int)

        return features

    def create_target(self, df: pd.DataFrame, features: pd.DataFrame) -> pd.DataFrame:
        features['next_up'] = (df['close'].shift(-1) > df['close']).astype(int)
        features['next_down'] = (df['close'].shift(-1) < df['close']).astype(int)
        self._log_features(features, "FINALS —Å target")
        return features

    def create_all_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """‚úÖ –ü–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –ë–ï–ó –°–ü–ê–ú–ê"""
        self._log_info("[Features]: –ó–∞–ø—É—Å–∫ –ø–∞–π–ø–ª–∞–π–Ω–∞...")

        # 1. –ë–∞–∑–æ–≤—ã–µ —Å–≤–µ—á–∏
        self._log_info("[Features]: 1/5 –ë–∞–∑–æ–≤—ã–µ —Å–≤–µ—á–∏...")
        base = self.create_candle_features(df)

        # 2. Volume
        self._log_info("[Features]: 2/5 Volume –∫–æ–º–±–æ...")
        vol_combos = self.add_volume_combos(base, df)

        # 3. MA
        self._log_info("[Features]: 3/5 –¢—Ä–µ–Ω–¥–æ–≤—ã–µ MA...")
        trend_features = self.add_trend_ma(df, vol_combos)

        # 4. Sequences
        self._log_info("[Features]: 4/5 –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏...")
        sequences = self.add_sequences(trend_features, df)

        # 5. Target
        self._log_info("[Features]: 5/5 Target...")
        final = self.create_target(df, sequences)

        return final
