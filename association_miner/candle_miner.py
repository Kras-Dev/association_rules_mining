from pathlib import Path
from association_miner.features_engineer import Features
from tqdm import tqdm
import pandas as pd
from typing import Dict, Optional, Tuple, Any

from back_test.config import SL_MULTIPLIER, ARM_CONFIG
from utils.base_file_handler import BaseFileHandler


class CandleMiner(BaseFileHandler):
    """
    CandleMiner: –ö–ª–∞—Å—Å –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –∑–Ω–∞—á–∏–º—ã—Ö —Å–≤–µ—á–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤.
    –ù–∞—Ö–æ–¥–∏—Ç –ø—Ä–∞–≤–∏–ª–∞ (features), –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—é—Ç –¥–≤–∏–∂–µ–Ω–∏–µ —Ü–µ–Ω—ã —Å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é (confidence) 60%+.
    """

    def __init__(self, min_confidence: float = 0.68, min_support: int = 22, verbose: bool = False,
                 history_dir: Path = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–∞–π–Ω–µ—Ä–∞ –ø—Ä–∞–≤–∏–ª.

        Args:
            min_confidence (float): –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å –ø—Ä–∞–≤–∏–ª–∞ (–æ—Ç 0 –¥–æ 1).
            min_support (int): –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—Ö–æ–∂–¥–µ–Ω–∏–π –ø–∞—Ç—Ç–µ—Ä–Ω–∞ –≤ –∏—Å—Ç–æ—Ä–∏–∏.
            verbose (bool): –§–ª–∞–≥ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è.
            history_dir (Path): –ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏/–º–æ–¥–µ–ª—è–º–∏.
        """
        super().__init__(verbose, history_dir)
        self.min_confidence = min_confidence
        self.min_support = min_support

    def save_rules(self, results: Dict, symbol: str, tf: str, min_confidence: float = None) -> str:
        """
        –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø—Ä–∞–≤–∏–ª –≤ –∫—ç—à (pickle).

        Args:
            results (Dict): –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ –∏–∑ find_strong_rules.
            symbol (str): –¢–æ—Ä–≥–æ–≤—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç.
            tf (str): –¢–∞–π–º—Ñ—Ä–µ–π–º.
            min_confidence (float): –ü–æ—Ä–æ–≥ —Ç–æ—á–Ω–æ—Å—Ç–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ "—Ç–æ–ø".

        Returns:
            str: –ü—É—Ç—å –∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É –∫—ç—à–∞.
        """
        if min_confidence is None:
            min_confidence = self.min_confidence

        cache_file = self._get_cache_path(symbol, tf)
        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø—Ä–∞–≤–∏–ª–∞: –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Å–∞–º—ã–µ –Ω–∞–¥–µ–∂–Ω—ã–µ –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞
        high_conf_rules = results['all_rules'][results['all_rules']['confidence'] >= min_confidence]
        rules_count = len(high_conf_rules)

        cache = {
            'top_rules': high_conf_rules,
            'base_prob_up': results['base_prob_up'],
            'base_prob_down': results['base_prob_down'],
            'symbol': symbol, 'tf': tf,
            'timestamp': pd.Timestamp.now(),
            'total_features': results.get('total_features', 0),
            'min_confidence': results.get('min_confidence', -1),
        }
        self._save_cache(cache_file, cache)
        self._log_info(f"[CandleMiner]: üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {cache_file} ({rules_count}/{len(results['all_rules'])} "
                       f">{min_confidence:.0%} conf –ø—Ä–∞–≤–∏–ª)")
        return str(cache_file)

    def load_rules(self, symbol: str, tf: str) -> Optional[Dict]:
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã—Ö –ø—Ä–∞–≤–∏–ª –∏–∑ –∫—ç—à–∞.
        """
        cache_path = self._get_cache_path(symbol, tf)
        data = self._load_cache(cache_path)
        if data:
            self._log_info(f"üìÇ –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {cache_path} ({len(data['top_rules'])} –ø—Ä–∞–≤–∏–ª)")
            return data
        self._log_warning(f"‚ùå –ö—ç—à –Ω–µ –Ω–∞–π–¥–µ–Ω –¥–ª—è {symbol} {tf} –ø–æ –ø—É—Ç–∏: {cache_path}")
        return None

    def find_strong_rules(self, features: pd.DataFrame) -> Optional[Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]]:
        """
        –û—Å–Ω–æ–≤–Ω–æ–π –∞–ª–≥–æ—Ä–∏—Ç–º –ø–æ–∏—Å–∫–∞ –∞—Å—Å–æ—Ü–∏–∞—Ç–∏–≤–Ω—ã—Ö –ø—Ä–∞–≤–∏–ª.
        –í—ã—á–∏—Å–ª—è–µ—Ç Confidence (—Ç–æ—á–Ω–æ—Å—Ç—å) –∏ Lift (–ø—Ä–µ–≤—ã—à–µ–Ω–∏–µ –Ω–∞–¥ –±–∞–∑–æ–≤–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é).
        """
        buy_conditions, sell_conditions = [], []
        # –û—Ç–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ –±–∏–Ω–∞—Ä–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (0 –∏–ª–∏ 1), –∏—Å–∫–ª—é—á–∞—è —Ü–µ–ª–µ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
        binary_features = [col for col in features.columns
                           if features[col].nunique() <= 2 and
                           col not in ['next_up', 'next_down']]

        self._log_info(f"–¢–µ—Å—Ç–∏—Ä—É–µ–º {len(binary_features)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")

        for feature in tqdm(binary_features, desc="Rules", unit="feature", disable=not self.verbose):
            # –°—á–∏—Ç–∞–µ–º, —Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ –≤—Å—Ç—Ä–µ—Ç–∏–ª—Å—è –¥–∞–Ω–Ω—ã–π –ø—Ä–∏–∑–Ω–∞–∫
            feature_series = features[feature]
            total = feature_series.sum()
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –ø–æ–¥–¥–µ—Ä–∂–∫—É (Support)
            if total < self.min_support:
                continue

            # --- –ê–Ω–∞–ª–∏–∑ –¥–ª—è LONG (UP) ---
            buy_hits = features[(features[feature] == 1) & (features['next_up'] == 1)].shape[0]
            buy_conf = buy_hits / total
            buy_lift = buy_conf / features['next_up'].mean() if features['next_up'].mean() > 0 else 1.0

            buy_conditions.append({'rule_name': feature, 'confidence': buy_conf,
                                       'support': total, 'lift': buy_lift,
                                       'direction': 'UP'})
            # --- –ê–Ω–∞–ª–∏–∑ –¥–ª—è SHORT (DOWN) ---
            sell_hits = features[(features[feature] == 1) & (features['next_down'] == 1)].shape[0]
            sell_conf = sell_hits / total
            sell_lift = sell_conf / features['next_down'].mean() if features['next_down'].mean() > 0 else 1.0

            sell_conditions.append({'rule_name': feature, 'confidence': sell_conf,
                                        'support': total, 'lift': sell_lift,
                                        'direction': 'DOWN'})
                # –°–±–æ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ DataFrame
        buy_rules = pd.DataFrame(buy_conditions)
        sell_rules = pd.DataFrame(sell_conditions)

        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ —Å–∏–ª–µ (Lift)
        if not buy_rules.empty:
            buy_rules = buy_rules.sort_values('lift', ascending=False).reset_index(drop=True)
        if not sell_rules.empty:
            sell_rules = sell_rules.sort_values('lift', ascending=False).reset_index(drop=True)

        all_rules = pd.concat([buy_rules, sell_rules], ignore_index=True)
        if not all_rules.empty:
            all_rules = all_rules.sort_values('lift', ascending=False).reset_index(drop=True)

        self._log_info(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {len(buy_rules)} BUY, {len(sell_rules)} SELL –ø—Ä–∞–≤–∏–ª.")
        return buy_rules, sell_rules, all_rules

    def smart_analyze(self, df: pd.DataFrame, symbol: str, timeframe: str) -> Dict:
        """
        –£–º–Ω—ã–π –∞–Ω–∞–ª–∏–∑: –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∑–∞–∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∞–≤–∏–ª–∞ –∏–ª–∏ –∑–∞–ø—É—Å–∫–∞–µ—Ç –Ω–æ–≤—ã–π –ø–æ–∏—Å–∫
        —Å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Å–∫–æ—Ä–æ—Å—Ç–∏.
        """
        # –ü–æ–∏—Å–∫ –Ω–∞—Å—Ç—Ä–æ–µ–∫ (–±–µ—Ä–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –∏–ª–∏ –¥–µ—Ñ–æ–ª—Ç)
        config = ARM_CONFIG.get(timeframe, {
            'min_support': self.min_support,
            'min_confidence': self.min_confidence
        })
        current_supp = config['min_support']
        current_conf = config['min_confidence']

        # 1. –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é "–º–æ–¥–µ–ª—å" –∏–∑ –∫—ç—à–∞
        cached = self._load_cache(self._get_cache_path(symbol, timeframe))
        if cached:
            self._log_info(f"‚úÖ –ö–≠–® –ê–ö–¢–£–ê–õ–ï–ù: {symbol} {timeframe} ({len(df)} —Å–≤–µ—á–µ–π)")
            return {
                'all_rules': cached['top_rules'],
                'base_prob_up': cached['base_prob_up'],
                'base_prob_down': cached['base_prob_down'],
                'symbol': symbol,
                'tf': timeframe,
                'from_cache': True,
                'min_confidence': cached['min_confidence'],

            }

        # 2. –ï—Å–ª–∏ –∫—ç—à–∞ –Ω–µ—Ç - –∑–∞–ø—É—Å–∫–∞–µ–º Feature Engineering
        self._log_info(f"üîç –ü–û–õ–ù–´–ô –ê–ù–ê–õ–ò–ó {symbol} {timeframe} (–°—Ç–∞—Ä—Ç –º–∞–π–Ω–∏–Ω–≥–∞)")

        feat_gen = Features(verbose=self.verbose)
        all_features = feat_gen.create_all_features(df)

        if all_features.empty:
            self._log_error("No features generated")
            return {'all_rules': pd.DataFrame(), 'error': 'No features generated'}

        # --- –î–ò–ù–ê–ú–ò–ß–ï–°–ö–ê–Ø –§–ò–õ–¨–¢–†–ê–¶–ò–Ø –ü–†–ò–ó–ù–ê–ö–û–í (–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è 2025) ---
        # –°—á–∏—Ç–∞–µ–º, –∫–∞–∫–æ–π % –æ—Ç –≤—Å–µ–π –∏—Å—Ç–æ—Ä–∏–∏ —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç —Ç–≤–æ–π min_support (21)
        # –ù–∞ D1 (3000 —Å–≤.) —ç—Ç–æ ~0.7%, –Ω–∞ H4 (6000 —Å–≤.) —ç—Ç–æ ~0.35%
        total_rows = len(all_features)
        dynamic_support_pct = current_supp / total_rows

        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Å–Ω–∏–∑—É (–Ω–µ –º–µ–Ω—å—à–µ 0.1%), —á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ–≥—Ä—É–∂–∞—Ç—å Apriori –Ω–∞ M15/H1
        effective_support_pct = max(0.001, dynamic_support_pct)
        min_support_count = total_rows * effective_support_pct

        initial_feat_count = all_features.shape[1]

        # –û—Ç–±–∏—Ä–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏, –≥–¥–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ "–µ–¥–∏–Ω–∏—Ü" (—Å–∏–≥–Ω–∞–ª–æ–≤) >= –ø–æ—Ä–æ–≥–∞
        # –ò—Å–∫–ª—é—á–∞–µ–º —Ü–µ–ª–µ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –∏–∑ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏, —á—Ç–æ–±—ã –æ–Ω–∏ –Ω–µ –ø—Ä–æ–ø–∞–ª–∏
        targets = ['next_up', 'next_down']
        cols_to_check = [c for c in all_features.columns if c not in targets]

        # –ë—ã—Å—Ç—Ä—ã–π –ø–æ–¥—Å—á–µ—Ç —Å—É–º–º –ø–æ –∫–æ–ª–æ–Ω–∫–∞–º
        feat_sums = all_features[cols_to_check].sum()
        keep_cols = feat_sums[feat_sums >= min_support_count].index.tolist()

        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø—Ä–∞–≤–∏–ª
        all_features_filtered = all_features[keep_cols + targets]

        self._log_info(f"–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è: –§–∏—á–∏ {initial_feat_count} -> {len(keep_cols) + 2} "
                       f"(–ü–æ—Ä–æ–≥: {effective_support_pct:.2%} –∏–ª–∏ {int(min_support_count)} –±–∞—Ä–æ–≤)")

        # 3. –ü–æ–∏—Å–∫ –∑–∞–∫–æ–Ω–æ–º–µ—Ä–Ω–æ—Å—Ç–µ–π (–Ω–∞ –æ–±–ª–µ–≥—á–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö)
        buy_rules, sell_rules, all_rules = self.find_strong_rules(all_features_filtered)

        # 4. –§–∏–ª—å—Ç—Ä—É–µ–º –¥–ª—è "—Å–∏–ª—å–Ω—ã—Ö" –ø—Ä–∞–≤–∏–ª —Å–æ–≥–ª–∞—Å–Ω–æ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–æ–º—É min_confidence (0.63)
        if not all_rules.empty:
            strong_rules = all_rules[all_rules['confidence'] >= current_conf]
        else:
            strong_rules = pd.DataFrame()

        base_prob_up = all_features['next_up'].mean()
        base_prob_down = all_features['next_down'].mean()

        if not strong_rules.empty:
            # 5. –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Å–ª–æ–≤–∞—Ä—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            results = {
                'all_rules': strong_rules,
                'base_prob_up': base_prob_up,
                'base_prob_down': base_prob_down,
                'symbol': symbol,
                'tf': timeframe,
                'total_features': len(keep_cols),
                'min_confidence': current_conf,
            }
            # 6. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ (–∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—Ä–æ–≥ –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞ –∫–ª–∞—Å—Å–∞)
            self.save_rules(results, symbol, timeframe, min_confidence=current_conf)
            self._log_info(f"üíæ –ù–∞–π–¥–µ–Ω–æ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(strong_rules)} –ø—Ä–∞–≤–∏–ª.")

            return {**results, 'from_cache': False}
        else:
            # –õ–æ–≥–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è –ø—Ä–∞–≤–∏–ª
            max_conf = all_rules['confidence'].max() if not all_rules.empty else 0
            self._log_warning(f"‚ö†Ô∏è –°–∏–ª—å–Ω—ã—Ö –ø—Ä–∞–≤–∏–ª (>{self.min_confidence}) –Ω–µ –Ω–∞–π–¥–µ–Ω–æ. "
                              f"–õ—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {max_conf:.2%}")
            return {'all_rules': pd.DataFrame(), 'error': 'No strong rules', 'from_cache': False}

    def get_dynamic_params(self, symbol: str, timeframe: str) -> Dict[str, Any]:
        """
        –î–ò–ù–ê–ú–ò–ß–ï–°–ö–ê–Ø –õ–û–ì–ò–ö–ê: conf + supp + SL_MULTIPLIER –ø–æ TF/–∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—É

        """
        current_conf = 0.68  # –ë–∞–∑–æ–≤—ã–π
        current_supp = 22  # –ë–∞–∑–æ–≤—ã–π
        sl_mult_key = symbol[:1]  # '#' –∏–ª–∏ 'r'

        # üî• TF-–õ–û–ì–ò–ö–ê (–ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É –∫–∞—á–µ—Å—Ç–≤–∞ —Å–∏–≥–Ω–∞–ª–æ–≤)
        if 'M15' in timeframe:
            current_supp = 35
            current_conf = 0.65  # ‚úÖ ROSN/SBER +35/+23%
        elif 'M30' in timeframe:
            current_supp = 35
            current_conf = 0.67  # ‚úÖ USDCAD/MOEX +10/+13%
        elif 'H1' in timeframe:
            current_supp = 25 if symbol.startswith('#') else 28
            current_conf = 0.70 if symbol.startswith('#') else 0.68  # MOEX H1 +19%
        elif 'H4' in timeframe:
            if symbol.startswith('#'):  # –ê–∫—Ü–∏–∏
                current_conf = 0.70
                current_supp = 25
            else:  # –§–æ—Ä–µ–∫—Å
                if symbol in ['USDCADrfd', 'EURUSDrfd']:
                    current_conf = 0.70
                    current_supp = 22  # EUR H4 Calmar 2.15
                else:  # GBPUSD, USDJPY
                    current_conf = 0.68
                    current_supp = 28
        elif 'D1' in timeframe:
            current_supp = 20
            current_conf = 0.72  # üèÜ MOEX D1 Calmar 5.32!

        # üî• SL_MULTIPLIER –ø–æ TF (–∂–µ—Å—Ç—á–µ = –º–µ–Ω—å—à–µ —à—É–º–∞)
        if 'M15' in timeframe or 'M30' in timeframe:
            SL_MULTIPLIER[sl_mult_key] = 2.2  # –®—É–º ‚Üí –∂–µ—Å—Ç–∫–∏–π SL
        elif 'D1' in timeframe:
            SL_MULTIPLIER[sl_mult_key] = 1.8  # –ß–∏—Å—Ç—ã–π —Å–∏–≥–Ω–∞–ª ‚Üí –º—è–≥–∫–∏–π SL
        elif 'H4' in timeframe:
            SL_MULTIPLIER[sl_mult_key] = 1.9 if symbol.startswith('#') else 2.0
        else:  # H1
            SL_MULTIPLIER[sl_mult_key] = 2.0

        return {
            'min_confidence': current_conf,
            'min_support': current_supp,
            'sl_multiplier_key': sl_mult_key,
            'sl_multiplier': SL_MULTIPLIER[sl_mult_key]
        }
