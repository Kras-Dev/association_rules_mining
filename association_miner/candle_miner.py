from pathlib import Path
from association_miner.features_engineer import Features
from tqdm import tqdm
import pandas as pd
from typing import Dict, Optional, Tuple

from utils.base_file_handler import BaseFileHandler


class CandleMiner(BaseFileHandler):
    """
    CandleMiner: –ö–ª–∞—Å—Å –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –∑–Ω–∞—á–∏–º—ã—Ö —Å–≤–µ—á–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤.
    –ù–∞—Ö–æ–¥–∏—Ç –ø—Ä–∞–≤–∏–ª–∞ (features), –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—é—Ç –¥–≤–∏–∂–µ–Ω–∏–µ —Ü–µ–Ω—ã —Å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é (confidence) 60%+.
    """

    def __init__(self, min_confidence: float = 0.60, min_support: int = 10, verbose: bool = False,
                 history_dir: Path = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–∞–π–Ω–µ—Ä–∞ –ø—Ä–∞–≤–∏–ª.

        Args:
            min_confidence (float): –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å –ø—Ä–∞–≤–∏–ª–∞ (–æ—Ç 0 –¥–æ 1).
            min_support (int): –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—Ö–æ–∂–¥–µ–Ω–∏–π –ø–∞—Ç—Ç–µ—Ä–Ω–∞ –≤ –∏—Å—Ç–æ—Ä–∏–∏.
            verbose (bool): –§–ª–∞–≥ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è.
            history_dir (Path): –ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏/–º–æ–¥–µ–ª—è–º–∏.
        """
        super().__init__(verbose, history_dir)
        self.min_confidence = min_confidence
        self.min_support = min_support

    def save_rules(self, results: Dict, symbol: str, tf: str, min_confidence: float = 0.70) -> str:
        """
        –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø—Ä–∞–≤–∏–ª –≤ –∫—ç—à (pickle).

        Args:
            results (Dict): –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ –∏–∑ find_strong_rules.
            symbol (str): –¢–æ—Ä–≥–æ–≤—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç.
            tf (str): –¢–∞–π–º—Ñ—Ä–µ–π–º.
            min_confidence (float): –ü–æ—Ä–æ–≥ —Ç–æ—á–Ω–æ—Å—Ç–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ "—Ç–æ–ø".

        Returns:
            str: –ü—É—Ç—å –∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É –∫—ç—à–∞.
        """
        cache_file = self._get_cache_path(symbol, tf)
        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø—Ä–∞–≤–∏–ª–∞: –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Å–∞–º—ã–µ –Ω–∞–¥–µ–∂–Ω—ã–µ –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞
        high_conf_rules = results['all_rules'][results['all_rules']['confidence'] >= min_confidence]
        rules_count = len(high_conf_rules)

        cache = {
            'top_rules': high_conf_rules,
            'base_prob_up': results['base_prob_up'],
            'base_prob_down': results['base_prob_down'],
            'symbol': symbol, 'tf': tf,
            'timestamp': pd.Timestamp.now(),
            'total_features': len(results['all_features'].columns)
        }
        self._save_pickle(cache_file, cache)
        self._log_info(f"[CandleMiner]: üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {cache_file} ({rules_count}/{len(results['all_rules'])} "
                       f">{min_confidence:.0%} conf –ø—Ä–∞–≤–∏–ª)")
        return str(cache_file)

    def load_rules(self, symbol: str, tf: str) -> Optional[Dict]:
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã—Ö –ø—Ä–∞–≤–∏–ª –∏–∑ –∫—ç—à–∞.
        """
        cache_path = self._get_cache_path(symbol, tf)
        data = self._load_pickle(cache_path)
        if data:
            self._log_info(f"üìÇ –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {cache_path} ({len(data['top_rules'])} –ø—Ä–∞–≤–∏–ª)")
            return data
        self._log_warning(f"‚ùå –ö—ç—à –Ω–µ –Ω–∞–π–¥–µ–Ω –¥–ª—è {symbol} {tf} –ø–æ –ø—É—Ç–∏: {cache_path}")
        return None

    def find_strong_rules(self, features: pd.DataFrame) -> Optional[Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]]:
        """
        –û—Å–Ω–æ–≤–Ω–æ–π –∞–ª–≥–æ—Ä–∏—Ç–º –ø–æ–∏—Å–∫–∞ –∞—Å—Å–æ—Ü–∏–∞—Ç–∏–≤–Ω—ã—Ö –ø—Ä–∞–≤–∏–ª.
        –í—ã—á–∏—Å–ª—è–µ—Ç Confidence (—Ç–æ—á–Ω–æ—Å—Ç—å) –∏ Lift (–ø—Ä–µ–≤—ã—à–µ–Ω–∏–µ –Ω–∞–¥ –±–∞–∑–æ–≤–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é).
        """
        buy_conditions, sell_conditions = [], []
        # –û—Ç–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ –±–∏–Ω–∞—Ä–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (0 –∏–ª–∏ 1), –∏—Å–∫–ª—é—á–∞—è —Ü–µ–ª–µ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
        binary_features = [col for col in features.select_dtypes(include=['int64']).columns
                           if col not in ['next_up', 'next_down']]

        mean_up = features['next_up'].mean()
        mean_down = features['next_down'].mean()

        self._log_info(f"–¢–µ—Å—Ç–∏—Ä—É–µ–º {len(binary_features)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")

        for feature in tqdm(binary_features, desc="Rules", unit="feature", disable=not self.verbose):
            # –°—á–∏—Ç–∞–µ–º, —Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ –≤—Å—Ç—Ä–µ—Ç–∏–ª—Å—è –¥–∞–Ω–Ω—ã–π –ø—Ä–∏–∑–Ω–∞–∫
            feature_series = features[feature]
            total = feature_series.sum()
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –ø–æ–¥–¥–µ—Ä–∂–∫—É (Support)
            if total < self.min_support:
                continue

            # --- –ê–Ω–∞–ª–∏–∑ –¥–ª—è LONG (UP) ---
            buy_hits = features[(features[feature] == 1) & (features['next_up'] == 1)].shape[0]
            buy_conf = buy_hits / total
            buy_lift = buy_conf / features['next_up'].mean() if features['next_up'].mean() > 0 else 1.0

            buy_conditions.append({'rule_name': feature, 'confidence': buy_conf,
                                       'support': total, 'lift': buy_lift,
                                       'direction': 'UP'})
            # --- –ê–Ω–∞–ª–∏–∑ –¥–ª—è SHORT (DOWN) ---
            sell_hits = features[(features[feature] == 1) & (features['next_down'] == 1)].shape[0]
            sell_conf = sell_hits / total
            sell_lift = sell_conf / features['next_down'].mean() if features['next_down'].mean() > 0 else 1.0

            sell_conditions.append({'rule_name': feature, 'confidence': sell_conf,
                                        'support': total, 'lift': sell_lift,
                                        'direction': 'DOWN'})
                # –°–±–æ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ DataFrame
        buy_rules = pd.DataFrame(buy_conditions)
        sell_rules = pd.DataFrame(sell_conditions)

        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ —Å–∏–ª–µ (Lift)
        if not buy_rules.empty:
            buy_rules = buy_rules.sort_values('lift', ascending=False).reset_index(drop=True)
        if not sell_rules.empty:
            sell_rules = sell_rules.sort_values('lift', ascending=False).reset_index(drop=True)

        all_rules = pd.concat([buy_rules, sell_rules], ignore_index=True)
        if not all_rules.empty:
            all_rules = all_rules.sort_values('lift', ascending=False).reset_index(drop=True)

        self._log_info(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {len(buy_rules)} BUY, {len(sell_rules)} SELL –ø—Ä–∞–≤–∏–ª.")
        return buy_rules, sell_rules, all_rules

    def smart_analyze(self, df: pd.DataFrame, symbol: str, timeframe: str) -> Dict:
        """
        –£–º–Ω—ã–π –∞–Ω–∞–ª–∏–∑: –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∑–∞–∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∞–≤–∏–ª–∞ –∏–ª–∏ –∑–∞–ø—É—Å–∫–∞–µ—Ç –Ω–æ–≤—ã–π –ø–æ–∏—Å–∫.
        """
        # 1. –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é "–º–æ–¥–µ–ª—å"
        cached = self.load_rules(symbol, timeframe)
        if cached:
            self._log_info(f"–ö–≠–® –ê–ö–¢–£–ê–õ–ï–ù ({len(df)} —Å–≤–µ—á–µ–π)")
            return {
                'all_rules': cached['top_rules'],
                'base_prob_up': cached['base_prob_up'],
                'base_prob_down': cached['base_prob_down'],
                'symbol': symbol, 'tf': timeframe, 'from_cache': True
            }
        # 2. –ï—Å–ª–∏ –∫—ç—à–∞ –Ω–µ—Ç - –∑–∞–ø—É—Å–∫–∞–µ–º Feature Engineering –∏ Mining
        self._log_info(f"–ü–û–õ–ù–´–ô –ê–ù–ê–õ–ò–ó {symbol} {timeframe}")

        feat_gen = Features(verbose=self.verbose)
        all_features = feat_gen.create_all_features(df)
        # 3. –ü–æ–∏—Å–∫ –∑–∞–∫–æ–Ω–æ–º–µ—Ä–Ω–æ—Å—Ç–µ–π
        buy_rules, sell_rules, all_rules = self.find_strong_rules(all_features)
        # –§–∏–ª—å—Ç—Ä—É–µ–º –¥–ª—è "—Å–∏–ª—å–Ω—ã—Ö" –ø—Ä–∞–≤–∏–ª (—Ç–µ—Ö, —á—Ç–æ –ø–æ–π–¥—É—Ç –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã)
        strong_rules = all_rules[all_rules['confidence'] >= self.min_confidence] \
                    if not all_rules.empty else pd.DataFrame()

        base_prob_up = all_features['next_up'].mean()
        base_prob_down = all_features['next_down'].mean()
        if not strong_rules.empty:
            # 4. –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Å–ª–æ–≤–∞—Ä—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            results = {
                'all_features': all_features, 'buy_rules': buy_rules, 'sell_rules': sell_rules,
                'all_rules': strong_rules, 'base_prob_up': base_prob_up, 'base_prob_down': base_prob_down,
                'symbol': symbol, 'tf_name': timeframe
            }
            # 5. –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            self.save_rules(results, symbol, timeframe, min_confidence=0.70)
        else:
            # –ù–∞—Ö–æ–¥–∏–º –ª—É—á—à–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ —Å—Ä–µ–¥–∏ –≤—Å–µ—Ö –ø–æ–ø—ã—Ç–æ–∫, –¥–∞–∂–µ –µ—Å–ª–∏ –æ–Ω–∏ —Å–ª–∞–±—ã–µ
            max_conf = all_rules['confidence'].max() if not all_rules.empty else 0
            max_lift = all_rules['lift'].max() if not all_rules.empty else 0
            msg = f"‚ö†Ô∏è –î–ª—è {symbol} {timeframe} —Å–∏–ª—å–Ω—ã—Ö –ø—Ä–∞–≤–∏–ª –Ω–µ –Ω–∞–π–¥–µ–Ω–æ."
            if max_conf > 0:
                msg += f" (–õ—É—á—à–∏–π Conf: {max_conf:.2%}, Lift: {max_lift:.2f})"

            self._log_warning(f"{msg}. –ö—ç—à –Ω–µ —Å–æ–∑–¥–∞–Ω.")
        return {'all_rules': pd.DataFrame(), 'error': 'No strong rules'}
