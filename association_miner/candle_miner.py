import logging
import os
import pickle
from tqdm import tqdm
import pandas as pd
from typing import Dict, Optional, Tuple
from association_miner.features_engineer import Features

logger = logging.getLogger(__name__)


class CandleMiner:
    """
    üî• –ö–ò–õ–õ–ï–†: –ù–∞—Ö–æ–¥–∏—Ç —Å–≤–µ—á–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Å confidence 60%+ –∏ lift >1.0
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç Features –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    """

    def __init__(self, min_confidence: float = 0.60, min_support: int = 20, verbose: bool = False):
        self.min_confidence = min_confidence
        self.min_support = min_support
        self.verbose = verbose

    def _log_features(self, features: pd.DataFrame, stage: str = "features") -> None:
        """–õ–æ–≥–≥–µ—Ä –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –±–∏–Ω–∞—Ä–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        if not self.verbose:
            return

        binary_cols = features.select_dtypes(include=['int64']).columns.tolist()
        logger.info(f"[CandleMiner]: ‚úÖ {len(binary_cols)} –±–∏–Ω–∞—Ä–Ω—ã—Ö {stage}!")

    def save_rules(self, results: Dict, symbol: str, tf: str, top_rules: int=100) -> str:
        """üíæ –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¢–û–ü-100 –ø—Ä–∞–≤–∏–ª –≤ rules_models/"""
        os.makedirs("models", exist_ok=True)
        cache_file = f"models/rules_{symbol}_{tf}.pkl"
        top_rules = results['all_rules'].head(top_rules)

        cache = {
            'top_rules': top_rules,
            'base_prob_up': results['base_prob_up'],
            'base_prob_down': results['base_prob_down'],
            'symbol': symbol,
            'tf': tf,
            'timestamp': pd.Timestamp.now(),
            'total_features': len(results['all_features'].columns)
        }
        with open(cache_file, 'wb') as f:
            pickle.dump(cache, f)
        print(f"[CandleMiner]: üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {cache_file} ({len(top_rules)} –ø—Ä–∞–≤–∏–ª)")
        return cache_file

    def load_rules(self, symbol: str, tf: str) -> Optional[Dict]:
        """üìÇ –ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø—Ä–∞–≤–∏–ª–∞ –∏–∑ rules_models/"""
        cache_file = f"models/rules_{symbol}_{tf}.pkl"
        if os.path.exists(cache_file):
            with open(cache_file, 'rb') as f:
                cache = pickle.load(f)
            print(f"[CandleMiner]: üìÇ –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {cache_file} ({len(cache['top_rules'])} –ø—Ä–∞–≤–∏–ª)")
            return cache
        print(f"[CandleMiner]: ‚ùå –ö—ç—à –Ω–µ –Ω–∞–π–¥–µ–Ω: {cache_file}")
        return None

    def _log_rules(self, buy_rules: pd.DataFrame, sell_rules: pd.DataFrame) -> None:
        """üìä –õ–æ–≥–≥–µ—Ä –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø—Ä–∞–≤–∏–ª"""
        if not self.verbose:
            return

        logger.info(f"[CandleMiner]: –ù–ê–ô–î–ï–ù–û: {len(buy_rules)} BUY, {len(sell_rules)} SELL –ø—Ä–∞–≤–∏–ª")
        logger.info(
            f"[CandleMiner]: –¢–û–ü BUY: {buy_rules.head(1)['confidence'].iloc[0]:.1%} ({buy_rules.head(1)['rule_name'].iloc[0]})")
        logger.info(
            f"[CandleMiner]: –¢–û–ü SELL: {sell_rules.head(1)['confidence'].iloc[0]:.1%} ({sell_rules.head(1)['rule_name'].iloc[0]})")


    def find_strong_rules(self, features: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:
        """
        –ù–∞—Ö–æ–¥–∏—Ç —Å–∏–ª—å–Ω—ã–µ –ø—Ä–∞–≤–∏–ª–∞ (confidence > min_confidence, support > min_support).

        Args:
            features: pd.DataFrame —Å –±–∏–Ω–∞—Ä–Ω—ã–º–∏ —Ñ–∏—á–∞–º–∏ + next_up/next_down

        Returns:
            (buy_rules, sell_rules, all_rules) ‚Äî –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ lift
        """
        buy_conditions, sell_conditions = [], []

        # TQD–ú –ø–æ –í–°–ï–ú –§–ò–ß–ê–ú
        binary_features = [col for col in features.select_dtypes(include=['int64']).columns
                           if col not in ['next_up', 'next_down']]

        if self.verbose:
            logger.info(f"[CandleMiner]: –¢–µ—Å—Ç–∏—Ä—É–µ–º {len(binary_features)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")

        # üî• –ü–†–û–ì–†–ï–°–°-–ë–ê–† –ü–û –§–ò–ß–ê–ú
        print(f"üîç –ê–Ω–∞–ª–∏–∑ {len(binary_features)} —Ñ–∏—á...")
        for feature in tqdm(binary_features, desc="Rules", unit="feature"):
            total = features[features[feature] == 1].shape[0]
            if total < self.min_support:
                continue

            # BUY: feature ‚Üí next_up
            buy_hits = features[(features[feature] == 1) & (features['next_up'] == 1)].shape[0]
            buy_conf = buy_hits / total
            buy_lift = buy_conf / features['next_up'].mean() if features['next_up'].mean() > 0 else 1.0

            # SELL: feature ‚Üí next_down
            sell_hits = features[(features[feature] == 1) & (features['next_down'] == 1)].shape[0]
            sell_conf = sell_hits / total
            sell_lift = sell_conf / features['next_down'].mean() if features['next_down'].mean() > 0 else 1.0

            if buy_conf > self.min_confidence:
                buy_conditions.append({
                    'rule_name': feature, 'confidence': buy_conf, 'support': total,
                    'lift': buy_lift, 'direction': 'UP'
                })

            if sell_conf > self.min_confidence:
                sell_conditions.append({
                    'rule_name': feature, 'confidence': sell_conf, 'support': total,
                    'lift': sell_lift, 'direction': 'DOWN'
                })

        buy_rules = pd.DataFrame(buy_conditions).sort_values('lift', ascending=False).reset_index(drop=True)
        sell_rules = pd.DataFrame(sell_conditions).sort_values('lift', ascending=False).reset_index(drop=True)
        all_rules = pd.concat([buy_rules, sell_rules], ignore_index=True) \
            .sort_values('lift', ascending=False) \
            .reset_index(drop=True)

        self._log_rules(buy_rules, sell_rules)
        return buy_rules, sell_rules, all_rules

    def print_top_rules(self, results: Dict, top_n: int = 20, symbol: str=None, timeframe: str=None) -> None:
        """
        –ö—Ä–∞—Å–∏–≤–æ –≤—ã–≤–æ–¥–∏—Ç –¢–û–ü-N –ª—É—á—à–∏—Ö –ø—Ä–∞–≤–∏–ª.

        Args:
            results: —Ä–µ–∑—É–ª—å—Ç–∞—Ç analyze()
            top_n: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–ø-–ø—Ä–∞–≤–∏–ª –¥–ª—è –≤—ã–≤–æ–¥–∞
            symbol: —Å–∏–º–≤–æ–ª –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞
            timeframe: —Ç–∞–π–º—Ñ—Ä–µ–π–º
        """
        all_rules = results['all_rules']
        if all_rules.empty:
            print("[CandleMiner]: ‚ùå –ù–µ—Ç —Å–∏–ª—å–Ω—ã—Ö –ø—Ä–∞–≤–∏–ª (confidence > {:.0%})".format(self.min_confidence))
            return

        print("\n" + "=" * 80)
        print(f"[CandleMiner]: –¢–û–ü-{top_n} –°–í–ï–ß–ù–´–• –ü–ê–¢–¢–ï–†–ù–û–í (conf > {self.min_confidence:.0%}) {symbol} {timeframe}")
        print("=" * 80)

        top = all_rules.head(top_n)
        for i, (_, rule) in enumerate(top.iterrows(), 1):
            emoji = "üü¢" if rule['direction'] == 'UP' else "üî¥"
            print(
                f"{i:2d}. {emoji} {rule['rule_name']:<40}",
                f"{rule['confidence']:.1%} –∫–æ–≥–¥–∞ —ç—Ç–æ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω —Å—Ä–∞–±–æ—Ç–∞–ª,",
                f"—Å–∏–ª–∞ —Å–∏–≥–Ω–∞–ª–∞(lift)={rule['lift']:.2f} ({int(rule['support'])} —Å–ª—É—á–∞—è)"
            )

        print("=" * 80)

    def analyze(self, df: pd.DataFrame, symbol: Optional[str] = None, timeframe: Optional[str] = None) -> Dict:
        """
        –ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑: Features ‚Üí Rules ‚Üí –†–µ–∑—É–ª—å—Ç–∞—Ç—ã.

        Args:
            df: DataFrame —Å OHLCV
            symbol: –Ω–∞–∑–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ (–¥–ª—è –ª–æ–≥–æ–≤)
            timeframe: —Ç–∞–π–º—Ñ—Ä–µ–π–º (–¥–ª—è –ª–æ–≥–æ–≤)

        Returns:
            Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞
        """
        print(f"[CandleMiner]: –ê–Ω–∞–ª–∏–∑ {symbol} {timeframe} ({len(df)} —Å–≤–µ—á–µ–π)...")
        if symbol and timeframe:
            logger.info(f"[CandleMiner]: –ê–Ω–∞–ª–∏–∑ {symbol} {timeframe}...")

        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤—Å–µ—Ö —Ñ–∏—á
        feat_gen = Features(verbose=self.verbose)
        all_features = feat_gen.create_all_features(df)

        self._log_features(all_features, "–ò–¢–û–ì–û–í–´–•")

        # –ü–æ–∏—Å–∫ –ø—Ä–∞–≤–∏–ª
        print("[CandleMiner]: –ü–æ–∏—Å–∫ —Å–∏–ª—å–Ω—ã—Ö –ø—Ä–∞–≤–∏–ª...")
        buy_rules, sell_rules, all_rules = self.find_strong_rules(all_features)

        # –ë–∞–∑–æ–≤—ã–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
        base_prob_up = all_features['next_up'].mean()
        base_prob_down = all_features['next_down'].mean()

        return {
            'all_features': all_features,
            'buy_rules': buy_rules,
            'sell_rules': sell_rules,
            'all_rules': all_rules,
            'base_prob_up': base_prob_up,
            'base_prob_down': base_prob_down,
            'symbol': symbol,
            'tf_name': timeframe
        }

    def smart_analyze(self, df: pd.DataFrame, symbol: str, timeframe: str) -> Dict:
        """–£–ú–ù–´–ô –∞–Ω–∞–ª–∏–∑: –∫—ç—à –ò–õ–ò –ø–æ–ª–Ω—ã–π –ø–µ—Ä–µ—Å—á—ë—Ç"""
        cached = self.load_rules(symbol, timeframe)
        if cached:
            print(f"[CandleMiner]: –ö–≠–® –ê–ö–¢–£–ê–õ–ï–ù ({len(df)} —Å–≤–µ—á–µ–π)")
            return {
                'all_rules': cached['top_rules'],
                'base_prob_up': cached['base_prob_up'],
                'base_prob_down': cached['base_prob_down'],
                'symbol': symbol,
                'tf': timeframe,
                'from_cache': True
            }

        print(f"[CandleMiner]: üî• –ü–û–õ–ù–´–ô –ê–ù–ê–õ–ò–ó ({len(df)} —Å–≤–µ—á–µ–π)")
        results = self.analyze(df, symbol, timeframe)
        self.save_rules(results, symbol, timeframe)
        return results


# –ü–†–ò–ú–ï–† –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Ø
"""
miner = CandleMiner(min_confidence=0.60, verbose=True)
results = miner.analyze(df, "EURUSD", "M5")
miner.print_top_rules(results, top_n=20)
"""
